{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5: Crating your own DNN for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# Import pytorch dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "\n",
    "# You cannot change this line.\n",
    "from tools.dataloader import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper-parameter\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VAL_BATCH_SIZE = 100\n",
    "TEST_BATCH_SIZE = 100\n",
    "INITIAL_LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "REG = 1e-2\n",
    "EPOCHS = 35\n",
    "CHECKPOINT_PATH = \"./saved_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading datasets\n",
    "data_path = './data/cifar10_train_val/cifar10-batches-'\n",
    "def load_dataset(dataset_type, data_path):\n",
    "    if dataset_type == 'train':\n",
    "        X = np.load(data_path + 'images-train.npy')\n",
    "        y = np.load(data_path + 'labels-train.npy')\n",
    "        return (X,y)\n",
    "        \n",
    "    if dataset_type == 'val':\n",
    "        X = np.load(data_path + 'images-val.npy')\n",
    "        y = np.load(data_path + 'labels-val.npy')\n",
    "        return (X,y)\n",
    "    \n",
    "    if dataset_type  == 'test':\n",
    "        X = np.load('./data/cifar10-batches-' + 'images-test.npy')\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform function\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding = 4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                        std=[0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                        std=[0.2023, 0.1994, 0.2010])])\n",
    "transform_test = transforms.Compose([\n",
    "    #transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                        std=[0.2023, 0.1994, 0.2010])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "class convert_data(Dataset):\n",
    "    def __init__(self, imgs, labels, transform):\n",
    "        self.X = imgs\n",
    "        self.y = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.fromarray(self.X[idx])\n",
    "        if self.transform != None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.y[idx]\n",
    "\n",
    "train_dataset = convert_data(load_dataset('train', data_path)[0], load_dataset('train', data_path)[1], transform = transform_train)\n",
    "val_dataset = convert_data(load_dataset('val', data_path)[0], load_dataset('val', data_path)[1], transform = transform_val)\n",
    "\n",
    "\n",
    "y_test_placeholder = [-1] * load_dataset('test', data_path).shape[0]\n",
    "test_dataset = convert_data(load_dataset('test', data_path), y_test_placeholder, transform = transform_test)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle = True, batch_size = TRAIN_BATCH_SIZE, num_workers = 1)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, shuffle = True, batch_size = VAL_BATCH_SIZE, num_workers = 1)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle = False, batch_size = TEST_BATCH_SIZE, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on GPU...\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device =='cuda':\n",
    "    print(\"Train on GPU...\")\n",
    "else:\n",
    "    print(\"Train on CPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# basicBlock is the basic unit of resNet, each block contains two convolution layers\n",
    "class basicBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputChannel, outputChannel, stride):\n",
    "        super(basicBlock, self).__init__()\n",
    "       \n",
    "        # the first convolution layer has stride of 1 or 2, depends on the function parameter \n",
    "        self.conv1 = nn.Conv2d(inputChannel, outputChannel, kernel_size = (3,3), stride = stride, padding = 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(outputChannel)\n",
    "        self.relu1 = nn.ReLU(inplace = True)\n",
    "        \n",
    "        # the second convolution layer always has stride of 1\n",
    "        self.conv2 = nn.Conv2d(outputChannel, outputChannel, kernel_size = (3,3), stride = 1, padding = 1, bias=False)\n",
    "        self.bn2= nn.BatchNorm2d(outputChannel)\n",
    "        \n",
    "        # x and F(x) are supposed to maintain the same dimension (inputchannel == outputchannel), then no downsampling needed\n",
    "        self.downsample = None\n",
    "    \n",
    "        if inputChannel != outputChannel or stride == 2:\n",
    "            # need downsampling on F(x) to match dimension, apply 1*1 kernel size, stride = 2\n",
    "            self.downsample = nn.Sequential(nn.Conv2d(inputChannel, outputChannel, kernel_size=(1,1), stride=stride, bias=False),\n",
    "                                            nn.BatchNorm2d(outputChannel))\n",
    "                                          \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample == None:\n",
    "            out += x       \n",
    "        else:\n",
    "            out += self.downsample(x)\n",
    "            \n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class resNet18(nn.Module):\n",
    "    \"\"\"\n",
    "    a resNet18 has one convolution layer and 4 other layers, each of them contains two blocks\n",
    "    \"\"\"\n",
    "    def __init__(self, basicBlock):\n",
    "        super(resNet18, self).__init__()\n",
    "        \n",
    "        #original channel\n",
    "        self.inputChannel = 64\n",
    "        \n",
    "        # first convolutional\n",
    "        self.conv0 = nn.Conv2d(3, 64, kernel_size = (3,3), stride = 1, padding = 1, bias=False)\n",
    "        self.batch0 = nn.BatchNorm2d(64)\n",
    "        self.relu0 = nn.ReLU()\n",
    "        \n",
    "        # each layer has two blocks, call generate_layer to connect each block in a layer       \n",
    "        self.layer1 = self.generate_layer(basicBlock, 64, 1)\n",
    "        self.layer2 = self.generate_layer(basicBlock, 128, 2)\n",
    "        self.layer3 = self.generate_layer(basicBlock, 256, 2)\n",
    "        self.layer4 = self.generate_layer(basicBlock, 512, 2)\n",
    "        \n",
    "        # output feature nnumber = 10\n",
    "        self.fully_connect = nn.Linear(512,10)\n",
    "        \n",
    "    def generate_layer(self, basicBlock, layerChannel, stride):\n",
    "        \"\"\" connect each block in a layer \n",
    "        parameters:\n",
    "        basicBlock: the minimal unit defined above of a resNet\n",
    "        layerChannel: number of channels in different layers\n",
    "        \"\"\"\n",
    "        # the first block starts with the stride defined in the funtion parameter for the first conv, and 1 for the secon conv\n",
    "        # the second block in each layer has a stride of 1 for both convs      \n",
    "        strideList = [stride, 1] \n",
    "        blockList = []\n",
    "        for i in range(2):\n",
    "            blockList.append(basicBlock(self.inputChannel, layerChannel, strideList[i]))\n",
    "            # update the input channel for the next layer\n",
    "            self.inputChannel = layerChannel\n",
    "            \n",
    "        return nn.Sequential(blockList[0], blockList[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.batch0(out)\n",
    "        out = self.relu0(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fully_connect(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send the model to GPU\n",
    "net = resNet18(basicBlock)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Add optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=INITIAL_LR, momentum=0.9, weight_decay=REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './saved_model/model_fz49.h5'\n",
      "Checkpoint not found.\n",
      "Training from scratch ...\n",
      "Starting from learning rate 0.010000:\n",
      "2019-10-11 01:42:40.662652\n",
      "Epoch 0:\n",
      "Training loss: 1.4812, Training accuracy: 0.4755\n",
      "2019-10-11 01:43:01.255472\n",
      "Validation...\n",
      "Validation loss: 1.1993, Validation accuracy: 0.5766\n",
      "Saving ...\n",
      "2019-10-11 01:43:03.157194\n",
      "Epoch 1:\n",
      "Training loss: 0.9400, Training accuracy: 0.6679\n",
      "2019-10-11 01:43:23.726380\n",
      "Validation...\n",
      "Validation loss: 0.8836, Validation accuracy: 0.6808\n",
      "Saving ...\n",
      "2019-10-11 01:43:25.833775\n",
      "Epoch 2:\n",
      "Training loss: 0.7595, Training accuracy: 0.7367\n",
      "2019-10-11 01:43:46.544914\n",
      "Validation...\n",
      "Validation loss: 0.8542, Validation accuracy: 0.7076\n",
      "Current learning rate has decayed to 0.008000\n",
      "Saving ...\n",
      "2019-10-11 01:43:48.243544\n",
      "Epoch 3:\n",
      "Training loss: 0.6325, Training accuracy: 0.7842\n",
      "2019-10-11 01:44:09.023547\n",
      "Validation...\n",
      "Validation loss: 0.7120, Validation accuracy: 0.7528\n",
      "Saving ...\n",
      "2019-10-11 01:44:11.111736\n",
      "Epoch 4:\n",
      "Training loss: 0.5937, Training accuracy: 0.7991\n",
      "2019-10-11 01:44:31.735358\n",
      "Validation...\n",
      "Validation loss: 0.7069, Validation accuracy: 0.7582\n",
      "Current learning rate has decayed to 0.006400\n",
      "Saving ...\n",
      "2019-10-11 01:44:33.708826\n",
      "Epoch 5:\n",
      "Training loss: 0.5169, Training accuracy: 0.8267\n",
      "2019-10-11 01:44:54.468820\n",
      "Validation...\n",
      "Validation loss: 0.8050, Validation accuracy: 0.7336\n",
      "2019-10-11 01:44:55.619339\n",
      "Epoch 6:\n",
      "Training loss: 0.4982, Training accuracy: 0.8351\n",
      "2019-10-11 01:45:16.215270\n",
      "Validation...\n",
      "Validation loss: 0.5592, Validation accuracy: 0.8064\n",
      "Current learning rate has decayed to 0.005120\n",
      "Saving ...\n",
      "2019-10-11 01:45:18.019784\n",
      "Epoch 7:\n",
      "Training loss: 0.4362, Training accuracy: 0.8576\n",
      "2019-10-11 01:45:38.747212\n",
      "Validation...\n",
      "Validation loss: 0.6940, Validation accuracy: 0.7658\n",
      "2019-10-11 01:45:39.940111\n",
      "Epoch 8:\n",
      "Training loss: 0.4157, Training accuracy: 0.8632\n",
      "2019-10-11 01:46:00.495297\n",
      "Validation...\n",
      "Validation loss: 0.5252, Validation accuracy: 0.8308\n",
      "Current learning rate has decayed to 0.004096\n",
      "Saving ...\n",
      "2019-10-11 01:46:02.618075\n",
      "Epoch 9:\n",
      "Training loss: 0.3684, Training accuracy: 0.8820\n",
      "2019-10-11 01:46:23.689737\n",
      "Validation...\n",
      "Validation loss: 0.5951, Validation accuracy: 0.8036\n",
      "2019-10-11 01:46:24.839491\n",
      "Epoch 10:\n",
      "Training loss: 0.3627, Training accuracy: 0.8813\n",
      "2019-10-11 01:46:45.470654\n",
      "Validation...\n",
      "Validation loss: 0.4895, Validation accuracy: 0.8386\n",
      "Current learning rate has decayed to 0.003277\n",
      "Saving ...\n",
      "2019-10-11 01:46:47.679801\n",
      "Epoch 11:\n",
      "Training loss: 0.3122, Training accuracy: 0.9014\n",
      "2019-10-11 01:47:08.420362\n",
      "Validation...\n",
      "Validation loss: 0.4964, Validation accuracy: 0.8382\n",
      "2019-10-11 01:47:09.603779\n",
      "Epoch 12:\n",
      "Training loss: 0.3005, Training accuracy: 0.9054\n",
      "2019-10-11 01:47:30.068518\n",
      "Validation...\n",
      "Validation loss: 0.5538, Validation accuracy: 0.8184\n",
      "Current learning rate has decayed to 0.002621\n",
      "2019-10-11 01:47:31.233879\n",
      "Epoch 13:\n",
      "Training loss: 0.2526, Training accuracy: 0.9228\n",
      "2019-10-11 01:47:51.869544\n",
      "Validation...\n",
      "Validation loss: 0.4431, Validation accuracy: 0.8552\n",
      "Saving ...\n",
      "2019-10-11 01:47:53.980620\n",
      "Epoch 14:\n",
      "Training loss: 0.2422, Training accuracy: 0.9243\n",
      "2019-10-11 01:48:14.861423\n",
      "Validation...\n",
      "Validation loss: 0.4519, Validation accuracy: 0.8528\n",
      "Current learning rate has decayed to 0.002097\n",
      "2019-10-11 01:48:16.020606\n",
      "Epoch 15:\n",
      "Training loss: 0.2004, Training accuracy: 0.9401\n",
      "2019-10-11 01:48:36.704000\n",
      "Validation...\n",
      "Validation loss: 0.4248, Validation accuracy: 0.8634\n",
      "Saving ...\n",
      "2019-10-11 01:48:38.879110\n",
      "Epoch 16:\n",
      "Training loss: 0.1904, Training accuracy: 0.9414\n",
      "2019-10-11 01:48:59.360014\n",
      "Validation...\n",
      "Validation loss: 0.4935, Validation accuracy: 0.8400\n",
      "Current learning rate has decayed to 0.001678\n",
      "2019-10-11 01:49:00.527102\n",
      "Epoch 17:\n",
      "Training loss: 0.1564, Training accuracy: 0.9553\n",
      "2019-10-11 01:49:21.480610\n",
      "Validation...\n",
      "Validation loss: 0.4030, Validation accuracy: 0.8708\n",
      "Saving ...\n",
      "2019-10-11 01:49:23.546200\n",
      "Epoch 18:\n",
      "Training loss: 0.1462, Training accuracy: 0.9582\n",
      "2019-10-11 01:49:44.192173\n",
      "Validation...\n",
      "Validation loss: 0.4809, Validation accuracy: 0.8478\n",
      "Current learning rate has decayed to 0.001342\n",
      "2019-10-11 01:49:45.304311\n",
      "Epoch 19:\n",
      "Training loss: 0.1189, Training accuracy: 0.9696\n",
      "2019-10-11 01:50:05.850437\n",
      "Validation...\n",
      "Validation loss: 0.3984, Validation accuracy: 0.8750\n",
      "Saving ...\n",
      "2019-10-11 01:50:07.806614\n",
      "Epoch 20:\n",
      "Training loss: 0.1008, Training accuracy: 0.9728\n",
      "2019-10-11 01:50:28.458684\n",
      "Validation...\n",
      "Validation loss: 0.3807, Validation accuracy: 0.8826\n",
      "Current learning rate has decayed to 0.001074\n",
      "Saving ...\n",
      "2019-10-11 01:50:30.177293\n",
      "Epoch 21:\n",
      "Training loss: 0.0858, Training accuracy: 0.9802\n",
      "2019-10-11 01:50:50.682639\n",
      "Validation...\n",
      "Validation loss: 0.3548, Validation accuracy: 0.8904\n",
      "Saving ...\n",
      "2019-10-11 01:50:52.568008\n",
      "Epoch 22:\n",
      "Training loss: 0.0794, Training accuracy: 0.9819\n",
      "2019-10-11 01:51:13.099454\n",
      "Validation...\n",
      "Validation loss: 0.3592, Validation accuracy: 0.8884\n",
      "Current learning rate has decayed to 0.000859\n",
      "2019-10-11 01:51:14.232566\n",
      "Epoch 23:\n",
      "Training loss: 0.0623, Training accuracy: 0.9887\n",
      "2019-10-11 01:51:35.011154\n",
      "Validation...\n",
      "Validation loss: 0.3088, Validation accuracy: 0.9080\n",
      "Saving ...\n",
      "2019-10-11 01:51:36.907801\n",
      "Epoch 24:\n",
      "Training loss: 0.0548, Training accuracy: 0.9907\n",
      "2019-10-11 01:51:57.707022\n",
      "Validation...\n",
      "Validation loss: 0.3328, Validation accuracy: 0.9032\n",
      "Current learning rate has decayed to 0.000687\n",
      "2019-10-11 01:51:58.831063\n",
      "Epoch 25:\n",
      "Training loss: 0.0467, Training accuracy: 0.9934\n",
      "2019-10-11 01:52:19.281312\n",
      "Validation...\n",
      "Validation loss: 0.3414, Validation accuracy: 0.9022\n",
      "2019-10-11 01:52:20.597229\n",
      "Epoch 26:\n",
      "Training loss: 0.0441, Training accuracy: 0.9942\n",
      "2019-10-11 01:52:41.497797\n",
      "Validation...\n",
      "Validation loss: 0.3106, Validation accuracy: 0.9098\n",
      "Current learning rate has decayed to 0.000550\n",
      "Saving ...\n",
      "2019-10-11 01:52:43.191404\n",
      "Epoch 27:\n",
      "Training loss: 0.0352, Training accuracy: 0.9970\n",
      "2019-10-11 01:53:03.780201\n",
      "Validation...\n",
      "Validation loss: 0.2910, Validation accuracy: 0.9170\n",
      "Saving ...\n",
      "2019-10-11 01:53:05.629481\n",
      "Epoch 28:\n",
      "Training loss: 0.0326, Training accuracy: 0.9976\n",
      "2019-10-11 01:53:26.083689\n",
      "Validation...\n",
      "Validation loss: 0.2883, Validation accuracy: 0.9154\n",
      "Current learning rate has decayed to 0.000440\n",
      "2019-10-11 01:53:27.199770\n",
      "Epoch 29:\n",
      "Training loss: 0.0283, Training accuracy: 0.9988\n",
      "2019-10-11 01:53:47.629247\n",
      "Validation...\n",
      "Validation loss: 0.2746, Validation accuracy: 0.9208\n",
      "Saving ...\n",
      "2019-10-11 01:53:50.037262\n",
      "Epoch 30:\n",
      "Training loss: 0.0274, Training accuracy: 0.9990\n",
      "2019-10-11 01:54:10.555277\n",
      "Validation...\n",
      "Validation loss: 0.2745, Validation accuracy: 0.9198\n",
      "Current learning rate has decayed to 0.000352\n",
      "2019-10-11 01:54:11.680638\n",
      "Epoch 31:\n",
      "Training loss: 0.0259, Training accuracy: 0.9995\n",
      "2019-10-11 01:54:32.293373\n",
      "Validation...\n",
      "Validation loss: 0.2720, Validation accuracy: 0.9246\n",
      "Saving ...\n",
      "2019-10-11 01:54:34.463086\n",
      "Epoch 32:\n",
      "Training loss: 0.0252, Training accuracy: 0.9995\n",
      "2019-10-11 01:54:55.253387\n",
      "Validation...\n",
      "Validation loss: 0.2740, Validation accuracy: 0.9246\n",
      "Current learning rate has decayed to 0.000281\n",
      "2019-10-11 01:54:56.388074\n",
      "Epoch 33:\n",
      "Training loss: 0.0249, Training accuracy: 0.9994\n",
      "2019-10-11 01:55:16.851744\n",
      "Validation...\n",
      "Validation loss: 0.2693, Validation accuracy: 0.9248\n",
      "Saving ...\n",
      "2019-10-11 01:55:19.095716\n",
      "Epoch 34:\n",
      "Training loss: 0.0246, Training accuracy: 0.9997\n",
      "2019-10-11 01:55:39.672013\n",
      "Validation...\n",
      "Validation loss: 0.2748, Validation accuracy: 0.9236\n",
      "Current learning rate has decayed to 0.000225\n",
      "Optimization finished.\n"
     ]
    }
   ],
   "source": [
    "# FLAG for loading the pretrained model\n",
    "TRAIN_FROM_SCRATCH = False\n",
    "# Code for loading checkpoint and recover epoch id.\n",
    "CKPT_PATH = \"./saved_model/model_fz49.h5\"\n",
    "def get_checkpoint(ckpt_path):\n",
    "    try:\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return ckpt\n",
    "\n",
    "ckpt = get_checkpoint(CKPT_PATH)\n",
    "if ckpt is None or TRAIN_FROM_SCRATCH:\n",
    "    if not TRAIN_FROM_SCRATCH:\n",
    "        print(\"Checkpoint not found.\")\n",
    "    print(\"Training from scratch ...\")\n",
    "    start_epoch = 0\n",
    "    current_learning_rate = INITIAL_LR\n",
    "else:\n",
    "    print(\"Successfully loaded checkpoint: %s\" %CKPT_PATH)\n",
    "    net.load_state_dict(ckpt['net'])\n",
    "    start_epoch = ckpt['epoch'] + 1\n",
    "    current_learning_rate = ckpt['lr']\n",
    "    print(\"Starting from epoch %d \" %start_epoch)\n",
    "\n",
    "print(\"Starting from learning rate %f:\" %current_learning_rate)\n",
    "\n",
    "global_step = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "trainloss_list = list()\n",
    "valloss_list = list()\n",
    "trainacc_list = list()\n",
    "valacc_list = list()\n",
    "\n",
    "for i in range(start_epoch, EPOCHS):\n",
    "    print(datetime.datetime.now())\n",
    "    # Switch to train mode\n",
    "    net.train()\n",
    "    print(\"Epoch %d:\" %i)\n",
    "\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    # Train the training dataset for 1 epoch.\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # Copy inputs to device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # Zero the gradient\n",
    "        optimizer.zero_grad()\n",
    "        # Generate output\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        # Now backward loss\n",
    "        loss.backward()\n",
    "        # Apply gradient\n",
    "        optimizer.step()\n",
    "        # Calculate predicted labels\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Calculate accuracy\n",
    "        total_examples += targets.size(0)\n",
    "        correct_examples += torch.sum(predicted == targets.data).float()\n",
    "\n",
    "        train_loss += loss\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step % 100 == 0:\n",
    "            avg_loss = train_loss / (batch_idx + 1)\n",
    "        pass\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    \n",
    "    trainloss_list.append(avg_loss)\n",
    "    trainacc_list.append(avg_acc)\n",
    "    \n",
    "    print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
    "    print(datetime.datetime.now())\n",
    "    # Validate on the validation dataset\n",
    "    print(\"Validation...\")\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    # Disable gradient during validation\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # Copy inputs to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # Zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "            # Generate output from the DNN.\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # Calculate predicted labels\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # Calculate accuracy\n",
    "            total_examples += targets.size(0)\n",
    "            correct_examples += torch.sum(predicted == targets.data).float()\n",
    "            val_loss += loss\n",
    "\n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
    "    \n",
    "    valloss_list.append(avg_loss)\n",
    "    valacc_list.append(avg_acc)\n",
    "    \n",
    "    DECAY_EPOCHS = 2\n",
    "    DECAY = 0.8\n",
    "    if i % DECAY_EPOCHS == 0 and i != 0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            # Assign the learning rate parameter\n",
    "            current_learning_rate = current_learning_rate*DECAY\n",
    "            param_group['lr'] = current_learning_rate\n",
    "            print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
    "    \n",
    "    # Save for checkpoint\n",
    "    if avg_acc > best_val_acc:\n",
    "        best_val_acc = avg_acc\n",
    "        if not os.path.exists(CHECKPOINT_PATH):\n",
    "            os.makedirs(CHECKPOINT_PATH)\n",
    "        print(\"Saving ...\")\n",
    "        state = {'net': net.state_dict(),\n",
    "                 'epoch': i,\n",
    "                 'lr': current_learning_rate}\n",
    "        torch.save(state, os.path.join(CHECKPOINT_PATH, 'model_fz49.h5'))\n",
    "\n",
    "print(\"Optimization finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "CKPT_PATH = \"./saved_models/model_fz49.h5\"\n",
    "ckpt = get_checkpoint(CKPT_PATH)\n",
    "net.load_state_dict(ckpt['net'])\n",
    "start_epoch = ckpt['epoch'] + 1\n",
    "current_learning_rate = ckpt['lr']\n",
    "\n",
    "def make_prediction(test_loader, TEST_BATCH_SIZE = TEST_BATCH_SIZE):\n",
    "    prediction = np.zeros([10000,2])\n",
    "    prediction[:,0] = np.arange(10000)\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            prediction[idx*TEST_BATCH_SIZE:(idx*TEST_BATCH_SIZE+len(predicted)), 1] =predicted.cpu().data.numpy()\n",
    "    np.savetxt('ECE590_prediction.csv', prediction.astype(int), fmt = \"%d\", delimiter=',', header='Id,Category', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
